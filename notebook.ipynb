{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc674037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report , confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc77c182",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_root = \"dataset\"\n",
    "output_root = \"augmented_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05ec4292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 247 images in class 'cardboard'\n",
      "Processed 385 images in class 'glass'\n",
      "Processed 315 images in class 'metal'\n",
      "Processed 449 images in class 'paper'\n",
      "Processed 363 images in class 'plastic'\n",
      "Processed 106 images in class 'trash'\n",
      "Minimum number of clean images across classes: 106\n"
     ]
    }
   ],
   "source": [
    "# Computing the minimum number of clean images per class\n",
    "minCleanImages = 9999999999\n",
    "for class_name in os.listdir(input_root):\n",
    "    class_path = os.path.join(input_root, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    # Create class folder inside augmented_dataset\n",
    "    output_class_path = os.path.join(output_root, class_name)\n",
    "    os.makedirs(output_class_path, exist_ok=True)\n",
    "    counter = 0\n",
    "    # Checking the number of images that are clean\n",
    "    for img_name in os.listdir(class_path):\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        counter+=1\n",
    "    minCleanImages = min(minCleanImages, counter)    \n",
    "    print(f\"Processed {counter} images in class '{class_name}'\")\n",
    "print(f\"Minimum number of clean images across classes: {minCleanImages}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b81e2ed",
   "metadata": {},
   "source": [
    "When augmenting the data, we want the sample size for each class to be similar, so we decided to set a limit for the augmentation size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28a2da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmentation Techniques\n",
    "def rotate_image(img, angle):\n",
    "    h, w = img.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1)\n",
    "    return cv2.warpAffine(img, M, (w, h))\n",
    "\n",
    "def add_gaussian_noise(img):\n",
    "    mean = 0\n",
    "    std = 5      # adjust noise level if needed\n",
    "    noise = np.random.normal(mean, std, img.shape).astype(np.uint8)\n",
    "    noisy_img = cv2.add(img, noise)\n",
    "    return noisy_img\n",
    "\n",
    "def change_brightness(img):\n",
    "    # Random brightness adjustment between -50 and +50\n",
    "    value = random.randint(-50, 50)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    # Convert to int32 to avoid overflow\n",
    "    v = v.astype(np.int32)\n",
    "    v = np.clip(v + value, 0, 255).astype(np.uint8)\n",
    "\n",
    "    final_hsv = cv2.merge((h, s, v))\n",
    "    bright_img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "    return bright_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8063c02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "numberOfAugmentationTecniques = 4 \n",
    "\n",
    "# Loop over classes\n",
    "for class_name in os.listdir(input_root):\n",
    "    class_path = os.path.join(input_root, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    # Create class folder inside augmented_dataset\n",
    "    output_class_path = os.path.join(output_root, class_name)\n",
    "    os.makedirs(output_class_path, exist_ok=True)\n",
    "    # duplicating original images and updating their name\n",
    "    for img_name in os.listdir(class_path):\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if img is None:\n",
    "            continue\n",
    "        filename = os.path.splitext(img_name)[0]\n",
    "        # Save original image\n",
    "        cv2.imwrite(os.path.join(output_class_path, f\"{filename}_orig.png\"), img)\n",
    "    # Loop over images\n",
    "    cnt = len(os.listdir(class_path))\n",
    "    for img_name in os.listdir(class_path):\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        filename = os.path.splitext(img_name)[0]\n",
    "        # ----- Augmentations -----\n",
    "        # 1. Flip\n",
    "        flipped = cv2.flip(img, 1)\n",
    "        cv2.imwrite(os.path.join(output_class_path, f\"{filename}_flip.png\"), flipped)\n",
    "        cnt += 1 \n",
    "        if ( cnt > minCleanImages * numberOfAugmentationTecniques ) :\n",
    "            break \n",
    "        # 2. Rotation\n",
    "        angle = random.randint(-30, 30)  # rotate between -30 to +30 degrees\n",
    "        rotated = rotate_image(img, angle)\n",
    "        cv2.imwrite(os.path.join(output_class_path, f\"{filename}_rot.png\"), rotated)\n",
    "        cnt += 1 \n",
    "        if ( cnt > minCleanImages * numberOfAugmentationTecniques ) :\n",
    "            break \n",
    "        # 3. Gaussian Noise\n",
    "        noisy = add_gaussian_noise(img)\n",
    "        cv2.imwrite(os.path.join(output_class_path, f\"{filename}_noise.png\"), noisy)\n",
    "        cnt += 1 \n",
    "        if ( cnt > minCleanImages * numberOfAugmentationTecniques ) :\n",
    "            break \n",
    "        # 4. Brightness Change\n",
    "        bright = change_brightness(img)\n",
    "        cv2.imwrite(os.path.join(output_class_path, f\"{filename}_bright.png\"), bright)\n",
    "        cnt += 1 \n",
    "        if ( cnt > minCleanImages * numberOfAugmentationTecniques ) :\n",
    "            break \n",
    "print(\"Augmentation completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "725d9b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []  # features\n",
    "y = []  # labels\n",
    "# Loop over classes\n",
    "for class_name in os.listdir(output_root):\n",
    "    class_path = os.path.join(output_root, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "    for img_name in os.listdir(class_path):\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        resized_image = cv2.resize(img,(384,384))\n",
    "        img_gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "        features = img_gray.flatten()\n",
    "        features = features / 255.0\n",
    "        X.append(features)\n",
    "        y.append(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00b1707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=7, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c14f9537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: [[0.56470588 0.57254902 0.57254902 ... 0.90588235 0.90588235 0.90588235]\n",
      " [0.80392157 0.81960784 0.83529412 ... 0.61176471 0.61568627 0.60392157]\n",
      " [0.74901961 0.74901961 0.74901961 ... 0.06666667 0.05098039 0.05490196]\n",
      " ...\n",
      " [0.68235294 0.70196078 0.69803922 ... 0.42745098 0.41960784 0.41176471]\n",
      " [0.69803922 0.69803922 0.69803922 ... 0.56862745 0.56862745 0.56862745]\n",
      " [0.75686275 0.76078431 0.76862745 ... 0.35686275 0.36470588 0.35686275]]\n",
      "X_test: [[0.58823529 0.58039216 0.58039216 ... 0.32941176 0.34901961 0.36470588]\n",
      " [0.96862745 0.98431373 0.99215686 ... 0.85490196 0.85490196 0.85098039]\n",
      " [0.98039216 0.94901961 0.98823529 ... 0.5372549  0.83529412 0.43529412]\n",
      " ...\n",
      " [0.90196078 0.90588235 0.90588235 ... 0.67058824 0.67058824 0.67058824]\n",
      " [0.92156863 0.92941176 0.93333333 ... 0.40784314 0.40784314 0.40392157]\n",
      " [0.8        0.8        0.79607843 ... 0.59215686 0.58823529 0.58823529]]\n",
      "y_train: ['plastic' 'cardboard' 'cardboard' ... 'cardboard' 'metal' 'cardboard']\n",
      "y_test: ['cardboard' 'paper' 'trash' 'cardboard' 'paper' 'cardboard' 'paper'\n",
      " 'plastic' 'glass' 'glass' 'plastic' 'cardboard' 'cardboard' 'glass'\n",
      " 'cardboard' 'paper' 'paper' 'plastic' 'trash' 'trash' 'trash' 'metal'\n",
      " 'paper' 'metal' 'paper' 'trash' 'paper' 'glass' 'cardboard' 'trash'\n",
      " 'plastic' 'metal' 'metal' 'cardboard' 'metal' 'cardboard' 'metal'\n",
      " 'cardboard' 'metal' 'glass' 'trash' 'plastic' 'metal' 'cardboard' 'metal'\n",
      " 'glass' 'paper' 'paper' 'glass' 'plastic' 'trash' 'glass' 'trash'\n",
      " 'cardboard' 'glass' 'trash' 'glass' 'glass' 'metal' 'plastic' 'paper'\n",
      " 'trash' 'glass' 'plastic' 'plastic' 'cardboard' 'trash' 'cardboard'\n",
      " 'trash' 'cardboard' 'plastic' 'trash' 'plastic' 'plastic' 'cardboard'\n",
      " 'glass' 'plastic' 'plastic' 'paper' 'metal' 'metal' 'plastic' 'trash'\n",
      " 'plastic' 'trash' 'cardboard' 'plastic' 'glass' 'trash' 'cardboard'\n",
      " 'glass' 'cardboard' 'plastic' 'glass' 'plastic' 'paper' 'paper'\n",
      " 'cardboard' 'plastic' 'paper' 'plastic' 'glass' 'metal' 'plastic' 'glass'\n",
      " 'trash' 'glass' 'glass' 'trash' 'trash' 'metal' 'paper' 'metal' 'glass'\n",
      " 'metal' 'glass' 'metal' 'trash' 'paper' 'cardboard' 'metal' 'plastic'\n",
      " 'cardboard' 'trash' 'paper' 'glass' 'trash' 'plastic' 'plastic' 'paper'\n",
      " 'trash' 'trash' 'metal' 'glass' 'metal' 'metal' 'metal' 'paper' 'trash'\n",
      " 'metal' 'cardboard' 'trash' 'cardboard' 'metal' 'paper' 'metal' 'metal'\n",
      " 'trash' 'trash' 'trash' 'cardboard' 'cardboard' 'metal' 'paper' 'glass'\n",
      " 'trash' 'metal' 'glass' 'glass' 'glass' 'cardboard' 'metal' 'glass'\n",
      " 'trash' 'paper' 'trash' 'paper' 'paper' 'plastic' 'trash' 'glass' 'glass'\n",
      " 'paper' 'paper' 'cardboard' 'plastic' 'cardboard' 'cardboard' 'plastic'\n",
      " 'trash' 'metal' 'paper' 'plastic' 'metal' 'plastic' 'paper' 'paper'\n",
      " 'metal' 'cardboard' 'glass' 'trash' 'paper' 'cardboard' 'trash' 'plastic'\n",
      " 'paper' 'metal' 'trash' 'trash' 'glass' 'metal' 'plastic' 'trash' 'glass'\n",
      " 'trash' 'trash' 'trash' 'metal' 'metal' 'paper' 'paper' 'trash' 'paper'\n",
      " 'metal' 'paper' 'paper' 'metal' 'paper' 'paper' 'trash' 'glass' 'paper'\n",
      " 'trash' 'plastic' 'trash' 'paper' 'metal' 'cardboard' 'trash' 'trash'\n",
      " 'glass' 'cardboard' 'trash' 'glass' 'metal' 'metal' 'glass' 'paper'\n",
      " 'cardboard' 'glass' 'paper' 'metal' 'metal' 'cardboard' 'cardboard'\n",
      " 'plastic' 'glass' 'plastic' 'glass' 'plastic' 'trash' 'trash' 'paper'\n",
      " 'metal' 'paper' 'metal' 'cardboard' 'trash' 'glass' 'cardboard'\n",
      " 'cardboard' 'metal' 'cardboard' 'plastic' 'trash' 'paper' 'metal' 'metal'\n",
      " 'plastic' 'paper' 'trash' 'cardboard' 'cardboard' 'cardboard' 'plastic'\n",
      " 'plastic' 'paper' 'metal' 'glass' 'glass' 'plastic' 'metal' 'plastic'\n",
      " 'paper' 'paper' 'plastic' 'plastic' 'metal' 'metal' 'cardboard'\n",
      " 'cardboard' 'cardboard' 'metal' 'metal' 'trash' 'metal' 'paper'\n",
      " 'cardboard' 'plastic' 'glass' 'trash' 'plastic' 'metal' 'trash'\n",
      " 'cardboard' 'glass' 'metal' 'metal' 'paper' 'trash' 'trash' 'glass'\n",
      " 'glass' 'cardboard' 'trash' 'plastic' 'metal' 'paper' 'trash' 'trash'\n",
      " 'trash' 'cardboard' 'cardboard' 'paper' 'cardboard' 'metal' 'glass'\n",
      " 'metal' 'plastic' 'metal' 'cardboard' 'glass' 'cardboard' 'paper' 'paper'\n",
      " 'trash' 'paper' 'plastic' 'paper' 'glass' 'trash' 'glass' 'glass' 'paper'\n",
      " 'cardboard' 'trash' 'glass' 'metal' 'metal' 'trash' 'glass' 'paper'\n",
      " 'paper' 'glass' 'paper' 'glass' 'metal' 'trash' 'cardboard' 'cardboard'\n",
      " 'glass' 'plastic' 'cardboard' 'glass' 'glass' 'plastic' 'glass'\n",
      " 'cardboard' 'cardboard' 'paper' 'glass' 'paper' 'trash' 'plastic'\n",
      " 'plastic' 'paper' 'plastic' 'cardboard' 'metal' 'metal' 'metal' 'paper'\n",
      " 'trash' 'plastic' 'glass' 'cardboard' 'plastic' 'metal' 'cardboard'\n",
      " 'trash' 'glass' 'trash' 'glass' 'metal' 'trash' 'paper' 'cardboard'\n",
      " 'plastic' 'glass' 'cardboard' 'paper' 'plastic' 'trash' 'metal'\n",
      " 'cardboard' 'cardboard' 'plastic' 'paper' 'trash' 'cardboard' 'plastic'\n",
      " 'trash' 'plastic' 'plastic' 'paper' 'trash' 'glass' 'plastic' 'paper'\n",
      " 'paper' 'glass' 'paper' 'glass' 'glass' 'cardboard' 'plastic' 'trash'\n",
      " 'plastic' 'paper' 'paper' 'plastic' 'glass' 'cardboard' 'trash' 'plastic'\n",
      " 'metal' 'plastic' 'cardboard' 'cardboard' 'glass' 'plastic' 'trash'\n",
      " 'plastic' 'plastic' 'glass' 'plastic' 'cardboard' 'paper' 'trash' 'glass'\n",
      " 'paper' 'paper' 'paper' 'paper' 'paper' 'plastic' 'paper' 'metal' 'metal'\n",
      " 'cardboard' 'cardboard' 'cardboard' 'metal' 'glass' 'metal' 'metal'\n",
      " 'cardboard' 'paper' 'glass' 'plastic' 'paper' 'glass' 'cardboard' 'paper'\n",
      " 'glass' 'plastic' 'trash' 'trash' 'paper' 'glass' 'plastic' 'glass'\n",
      " 'metal' 'cardboard' 'metal' 'glass' 'cardboard' 'cardboard' 'plastic'\n",
      " 'paper' 'plastic' 'paper' 'metal' 'plastic' 'metal' 'metal' 'paper'\n",
      " 'metal' 'cardboard' 'glass' 'paper' 'plastic']\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train:\", X_train)\n",
    "print(\"X_test:\", X_test)\n",
    "print(\"y_train:\", y_train)\n",
    "print(\"y_test:\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5bceba2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.44223107569721115\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   cardboard       0.38      0.61      0.47        83\n",
      "       glass       0.44      0.40      0.42        82\n",
      "       metal       0.58      0.18      0.28        83\n",
      "       paper       0.50      0.36      0.42        90\n",
      "     plastic       0.40      0.60      0.48        80\n",
      "       trash       0.52      0.51      0.51        84\n",
      "\n",
      "    accuracy                           0.44       502\n",
      "   macro avg       0.47      0.44      0.43       502\n",
      "weighted avg       0.47      0.44      0.43       502\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[51  6  2  9  8  7]\n",
      " [13 33  4  7 20  5]\n",
      " [28  9 15  4 13 14]\n",
      " [18  7  1 32 23  9]\n",
      " [10  9  0  8 48  5]\n",
      " [14 11  4  4  8 43]]\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)  # you can choose k\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Optional: detailed classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Optional: confusion matrix\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
